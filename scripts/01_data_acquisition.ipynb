{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching S&P 500 ticker list from Wikipedia...\n",
      "Found 504 tickers.\n",
      "['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "def get_sp500_tickers():\n",
    "    \"\"\"Scrapes the list of S&P 500 tickers from Wikipedia.\"\"\"\n",
    "    print(\"Fetching S&P 500 ticker list from Wikipedia...\")\n",
    "    \n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    \n",
    "    # Add a User-Agent header to mimic a real browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    # Make the request with the new headers\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Use StringIO to wrap the text, which is the modern way to use read_html\n",
    "    tables = pd.read_html(StringIO(response.text))\n",
    "    \n",
    "    # The rest of your function remains the same\n",
    "    sp500_df = tables[0]\n",
    "    tickers = sp500_df['Symbol'].str.replace('.', '-', regex=False).tolist()\n",
    "    print(f\"Found {len(tickers)} tickers.\")\n",
    "    return tickers\n",
    "\n",
    "# Get the list\n",
    "sp500_tickers = get_sp500_tickers()\n",
    "print(sp500_tickers[:10]) # Print first 10 to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vader lexicon is ready.\n",
      "\n",
      "Starting data collection for all S&P 500 stocks...\n",
      "Processing 1/504: MMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:31: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_df = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n",
      "08/28/2025 06:50:46 PM - ('Connection aborted.', OSError(22, 'Invalid argument'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  No news for MMM. Proceeding without sentiment.\n",
      "Processing 2/504: AOS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:31: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_df = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  stock_df['sentiment'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:60: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  stock_df['sentiment'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  stock_df['sentiment'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3/504: ABT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:31: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_df = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  stock_df['sentiment'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:60: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  stock_df['sentiment'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  stock_df['sentiment'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4/504: ABBV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:31: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_df = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  stock_df['sentiment'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:60: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  stock_df['sentiment'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  stock_df['sentiment'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5/504: ACN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:31: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_df = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  stock_df['sentiment'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:60: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  stock_df['sentiment'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  stock_df['sentiment'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6/504: ADBE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:31: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_df = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  stock_df['sentiment'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:60: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  stock_df['sentiment'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/st/8z9yjrgn4fq_j2pyt73wn7d00000gn/T/ipykernel_9528/138501306.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  stock_df['sentiment'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combining all data into a single DataFrame...\n",
      "\n",
      "--- Final Combined Dataset ---\n",
      "                 Close        High         Low        Open   Volume  \\\n",
      "Date                                                                  \n",
      "2025-07-29  151.091873  152.395861  150.454817  151.699068  3918100   \n",
      "2025-07-30  145.945648  151.798609  145.826205  151.778697  3529500   \n",
      "2025-07-31  148.533691  148.872124  144.890521  145.517629  4390400   \n",
      "2025-08-01  143.745819  146.045192  143.586551  145.826203  4074400   \n",
      "2025-08-04  147.189896  147.498467  144.333101  144.721306  3641300   \n",
      "\n",
      "            sentiment ticker  \n",
      "Date                          \n",
      "2025-07-29        0.0    MMM  \n",
      "2025-07-30        0.0    MMM  \n",
      "2025-07-31        0.0    MMM  \n",
      "2025-08-01        0.0    MMM  \n",
      "2025-08-04        0.0    MMM  \n",
      "...\n",
      "                 Close        High         Low        Open   Volume  \\\n",
      "Date                                                                  \n",
      "2025-08-21  353.429993  353.820007  347.000000  349.910004  2363200   \n",
      "2025-08-22  362.089996  362.649994  354.000000  355.799988  3058600   \n",
      "2025-08-25  363.209991  364.649994  361.399994  362.559998  2259500   \n",
      "2025-08-26  354.910004  363.230011  353.700012  363.029999  4067400   \n",
      "2025-08-27  356.350006  360.369995  355.160004  355.980011  2353800   \n",
      "\n",
      "            sentiment ticker  \n",
      "Date                          \n",
      "2025-08-21   0.000000   ADBE  \n",
      "2025-08-22   0.000000   ADBE  \n",
      "2025-08-25   0.012240   ADBE  \n",
      "2025-08-26   0.118087   ADBE  \n",
      "2025-08-27  -0.318200   ADBE  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from gnews import GNews\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "import nltk\n",
    "\n",
    "# --- NLTK Setup ---\n",
    "try:\n",
    "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
    "except LookupError:\n",
    "    print(\"Vader lexicon not found. Downloading...\")\n",
    "    nltk.download('vader_lexicon')\n",
    "print(\"Vader lexicon is ready.\")\n",
    "\n",
    "# --- Parameters ---\n",
    "END_DATE = date.today()\n",
    "START_DATE = END_DATE - timedelta(days=30)\n",
    "\n",
    "# --- Initialize ---\n",
    "gnews = GNews(start_date=START_DATE, end_date=END_DATE)\n",
    "sia = SentimentIntensityAnalyzer() # Initialize it once here\n",
    "all_dataframes = []\n",
    "# --- Main Loop ---\n",
    "print(\"\\nStarting data collection for all S&P 500 stocks...\")\n",
    "for i, ticker in enumerate(sp500_tickers[:6]):\n",
    "    print(f\"Processing {i+1}/{len(sp500_tickers)}: {ticker}\")\n",
    "    try:\n",
    "        # --- 1. Fetch Stock Data ---\n",
    "        stock_df = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n",
    "        \n",
    "        # !!! THIS IS THE CRITICAL FIX !!!\n",
    "        # Flatten the multi-level column index if it exists\n",
    "        if isinstance(stock_df.columns, pd.MultiIndex):\n",
    "            stock_df.columns = stock_df.columns.droplevel(1)\n",
    "\n",
    "        if stock_df.empty:\n",
    "            print(f\"  No stock data for {ticker}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # --- 2. Fetch News Data ---\n",
    "        news_articles = gnews.get_news(f'{ticker} stock')\n",
    "        if not news_articles:\n",
    "            print(f\"  No news for {ticker}. Proceeding without sentiment.\")\n",
    "            stock_df['sentiment'] = 0.0\n",
    "        else:\n",
    "            news_df = pd.DataFrame(news_articles)\n",
    "            # --- 3. Perform Sentiment Analysis ---\n",
    "            news_df['sentiment'] = news_df['title'].apply(lambda title: sia.polarity_scores(title)['compound'])\n",
    "            news_df['date'] = pd.to_datetime(news_df['published date']).dt.date\n",
    "            \n",
    "            # --- 4. Combine Datasets ---\n",
    "            daily_sentiment = news_df.groupby('date')['sentiment'].mean()\n",
    "            daily_sentiment.index = pd.to_datetime(daily_sentiment.index)\n",
    "            \n",
    "            # Now the .join() will work because the columns are simple\n",
    "            stock_df = stock_df.join(daily_sentiment, how='left')\n",
    "            \n",
    "            stock_df['sentiment'].fillna(method='ffill', inplace=True)\n",
    "            stock_df['sentiment'].fillna(0, inplace=True)\n",
    "\n",
    "        # Add a ticker column for identification\n",
    "        stock_df['ticker'] = ticker\n",
    "        all_dataframes.append(stock_df)\n",
    "\n",
    "        # IMPORTANT: Pause to be respectful to the APIs\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  An error occurred for {ticker}: {e}\")\n",
    "\n",
    "# --- Final Combination ---\n",
    "print(\"\\nCombining all data into a single DataFrame...\")\n",
    "# This will now work because all_dataframes will not be empty\n",
    "if all_dataframes:\n",
    "    final_df = pd.concat(all_dataframes)\n",
    "    print(\"\\n--- Final Combined Dataset ---\")\n",
    "    print(final_df.head())\n",
    "    print(\"...\")\n",
    "    print(final_df.tail())\n",
    "else:\n",
    "    print(\"No data was collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-07-29</th>\n",
       "      <td>151.091873</td>\n",
       "      <td>152.395861</td>\n",
       "      <td>150.454817</td>\n",
       "      <td>151.699068</td>\n",
       "      <td>3918100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-30</th>\n",
       "      <td>145.945648</td>\n",
       "      <td>151.798609</td>\n",
       "      <td>145.826205</td>\n",
       "      <td>151.778697</td>\n",
       "      <td>3529500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-31</th>\n",
       "      <td>148.533691</td>\n",
       "      <td>148.872124</td>\n",
       "      <td>144.890521</td>\n",
       "      <td>145.517629</td>\n",
       "      <td>4390400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-01</th>\n",
       "      <td>143.745819</td>\n",
       "      <td>146.045192</td>\n",
       "      <td>143.586551</td>\n",
       "      <td>145.826203</td>\n",
       "      <td>4074400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-04</th>\n",
       "      <td>147.189896</td>\n",
       "      <td>147.498467</td>\n",
       "      <td>144.333101</td>\n",
       "      <td>144.721306</td>\n",
       "      <td>3641300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-21</th>\n",
       "      <td>353.429993</td>\n",
       "      <td>353.820007</td>\n",
       "      <td>347.000000</td>\n",
       "      <td>349.910004</td>\n",
       "      <td>2363200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ADBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-22</th>\n",
       "      <td>362.089996</td>\n",
       "      <td>362.649994</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>355.799988</td>\n",
       "      <td>3058600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ADBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-25</th>\n",
       "      <td>363.209991</td>\n",
       "      <td>364.649994</td>\n",
       "      <td>361.399994</td>\n",
       "      <td>362.559998</td>\n",
       "      <td>2259500</td>\n",
       "      <td>0.012240</td>\n",
       "      <td>ADBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-26</th>\n",
       "      <td>354.910004</td>\n",
       "      <td>363.230011</td>\n",
       "      <td>353.700012</td>\n",
       "      <td>363.029999</td>\n",
       "      <td>4067400</td>\n",
       "      <td>0.118087</td>\n",
       "      <td>ADBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-27</th>\n",
       "      <td>356.350006</td>\n",
       "      <td>360.369995</td>\n",
       "      <td>355.160004</td>\n",
       "      <td>355.980011</td>\n",
       "      <td>2353800</td>\n",
       "      <td>-0.318200</td>\n",
       "      <td>ADBE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Close        High         Low        Open   Volume  \\\n",
       "Date                                                                  \n",
       "2025-07-29  151.091873  152.395861  150.454817  151.699068  3918100   \n",
       "2025-07-30  145.945648  151.798609  145.826205  151.778697  3529500   \n",
       "2025-07-31  148.533691  148.872124  144.890521  145.517629  4390400   \n",
       "2025-08-01  143.745819  146.045192  143.586551  145.826203  4074400   \n",
       "2025-08-04  147.189896  147.498467  144.333101  144.721306  3641300   \n",
       "...                ...         ...         ...         ...      ...   \n",
       "2025-08-21  353.429993  353.820007  347.000000  349.910004  2363200   \n",
       "2025-08-22  362.089996  362.649994  354.000000  355.799988  3058600   \n",
       "2025-08-25  363.209991  364.649994  361.399994  362.559998  2259500   \n",
       "2025-08-26  354.910004  363.230011  353.700012  363.029999  4067400   \n",
       "2025-08-27  356.350006  360.369995  355.160004  355.980011  2353800   \n",
       "\n",
       "            sentiment ticker  \n",
       "Date                          \n",
       "2025-07-29   0.000000    MMM  \n",
       "2025-07-30   0.000000    MMM  \n",
       "2025-07-31   0.000000    MMM  \n",
       "2025-08-01   0.000000    MMM  \n",
       "2025-08-04   0.000000    MMM  \n",
       "...               ...    ...  \n",
       "2025-08-21   0.000000   ADBE  \n",
       "2025-08-22   0.000000   ADBE  \n",
       "2025-08-25   0.012240   ADBE  \n",
       "2025-08-26   0.118087   ADBE  \n",
       "2025-08-27  -0.318200   ADBE  \n",
       "\n",
       "[132 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [0.81916305],\n",
       "       [0.64885281],\n",
       "       [0.38191598],\n",
       "       [0.14035114],\n",
       "       [0.13738175],\n",
       "       [0.3230768 ],\n",
       "       [0.12469616],\n",
       "       [0.19972983],\n",
       "       [0.        ],\n",
       "       [0.12901475],\n",
       "       [0.47017557],\n",
       "       [0.40296856],\n",
       "       [0.57219978],\n",
       "       [0.63670674],\n",
       "       [0.73900112],\n",
       "       [0.53387285],\n",
       "       [0.53387285],\n",
       "       [0.76761102],\n",
       "       [0.7978403 ],\n",
       "       [0.57381914],\n",
       "       [0.61268559]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume 'final_df' is your loaded DataFrame\n",
    "# For this example, we'll focus on a single stock\n",
    "ticker_to_predict = 'ADBE'\n",
    "df_stock = final_df[final_df['ticker'] == ticker_to_predict].copy()\n",
    "\n",
    "# We'll use 'Close' price and 'sentiment' as features\n",
    "data = df_stock[['Close', 'sentiment']].values\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Create a separate scaler just for the 'Close' price for easy inverse transformation later\n",
    "scaler_price = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_price.fit_transform(df_stock[['Close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOK_BACK = 60\n",
    "PREDICT_DAYS = 30\n",
    "\n",
    "X_train, y_train = [], []\n",
    "\n",
    "for i in range(LOOK_BACK, len(scaled_data) - PREDICT_DAYS):\n",
    "    # X contains the last 60 days of [Close, sentiment]\n",
    "    X_train.append(scaled_data[i-LOOK_BACK:i])\n",
    "    # y contains the next 30 days of just the 'Close' price\n",
    "    y_train.append(scaled_data[i:i+PREDICT_DAYS, 0])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# First LSTM layer\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])))\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.2\u001b[39m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Second LSTM layer\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First LSTM layer\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Second LSTM layer\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer - predicts 30 values\n",
    "model.add(Dense(units=PREDICT_DAYS))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
